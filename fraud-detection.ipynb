{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Fraud Detection using autoencoder</h1>\n",
    "\n",
    "In this notebook we will study fraud detection by analysing transaction's temporal and sequential dimensions.\n",
    "\n",
    "<h2>1. Analyse the data:</h2>\n",
    "\n",
    "* How many features do we have ?\n",
    "* What the feature is used for ?\n",
    "* How many NaN do we have ?\n",
    "* Which feature is not essential for solving the problem ?\n",
    "\n",
    "<h3>Train Identity dataset:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>id_01</th>\n",
       "      <th>id_02</th>\n",
       "      <th>id_03</th>\n",
       "      <th>id_04</th>\n",
       "      <th>id_05</th>\n",
       "      <th>id_06</th>\n",
       "      <th>id_07</th>\n",
       "      <th>id_08</th>\n",
       "      <th>id_09</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70787.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>samsung browser 6.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2220x1080</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987008</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>98945.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile safari 11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1334x750</td>\n",
       "      <td>match_status:1</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>iOS Device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987010</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>191631.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987011</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>221832.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>desktop</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7460.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 62.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1280x800</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>desktop</td>\n",
       "      <td>MacOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  id_01     id_02  id_03  id_04  id_05  id_06  id_07  id_08  \\\n",
       "0        2987004    0.0   70787.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1        2987008   -5.0   98945.0    NaN    NaN    0.0   -5.0    NaN    NaN   \n",
       "2        2987010   -5.0  191631.0    0.0    0.0    0.0    0.0    NaN    NaN   \n",
       "3        2987011   -5.0  221832.0    NaN    NaN    0.0   -6.0    NaN    NaN   \n",
       "4        2987016    0.0    7460.0    0.0    0.0    1.0    0.0    NaN    NaN   \n",
       "\n",
       "   id_09  ...                id_31  id_32      id_33           id_34  id_35  \\\n",
       "0    NaN  ...  samsung browser 6.2   32.0  2220x1080  match_status:2      T   \n",
       "1    NaN  ...   mobile safari 11.0   32.0   1334x750  match_status:1      T   \n",
       "2    0.0  ...          chrome 62.0    NaN        NaN             NaN      F   \n",
       "3    NaN  ...          chrome 62.0    NaN        NaN             NaN      F   \n",
       "4    0.0  ...          chrome 62.0   24.0   1280x800  match_status:2      T   \n",
       "\n",
       "  id_36 id_37  id_38  DeviceType                     DeviceInfo  \n",
       "0     F     T      T      mobile  SAMSUNG SM-G892A Build/NRD90M  \n",
       "1     F     F      T      mobile                     iOS Device  \n",
       "2     F     T      T     desktop                        Windows  \n",
       "3     F     T      T     desktop                            NaN  \n",
       "4     F     T      T     desktop                          MacOS  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "datasetPath = ''\n",
    "\n",
    "trainID = pd.read_csv(datasetPath+'train_identity.csv', encoding='utf-8')\n",
    "trainID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_24            96.708798\n",
       "id_25            96.441868\n",
       "id_07            96.425922\n",
       "id_08            96.425922\n",
       "id_21            96.423149\n",
       "id_26            96.420375\n",
       "id_23            96.416215\n",
       "id_27            96.416215\n",
       "id_22            96.416215\n",
       "id_18            68.722137\n",
       "id_03            54.016071\n",
       "id_04            54.016071\n",
       "id_33            49.187079\n",
       "id_09            48.052110\n",
       "id_10            48.052110\n",
       "id_30            46.222432\n",
       "id_32            46.207872\n",
       "id_34            46.056034\n",
       "id_14            44.503685\n",
       "DeviceInfo       17.726179\n",
       "id_13            11.726165\n",
       "id_16            10.325654\n",
       "id_06             5.108401\n",
       "id_05             5.108401\n",
       "id_20             3.447200\n",
       "id_19             3.407681\n",
       "id_17             3.372321\n",
       "id_31             2.739318\n",
       "DeviceType        2.373243\n",
       "id_02             2.330257\n",
       "id_28             2.256765\n",
       "id_29             2.256765\n",
       "id_11             2.256765\n",
       "id_15             2.251912\n",
       "id_35             2.251912\n",
       "id_36             2.251912\n",
       "id_37             2.251912\n",
       "id_38             2.251912\n",
       "id_01             0.000000\n",
       "id_12             0.000000\n",
       "TransactionID     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((trainID.isna().sum()/trainID.shape[0])*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns have 96% NaN values !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train Transaction dataset:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN   NaN  \n",
       "4  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTR = pd.read_csv(datasetPath+'train_transaction.csv', encoding='utf-8')\n",
    "trainTR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dist2            93.628374\n",
       "D7               93.409930\n",
       "D13              89.509263\n",
       "D14              89.469469\n",
       "D12              89.041047\n",
       "                   ...    \n",
       "C1                0.000000\n",
       "C2                0.000000\n",
       "C14               0.000000\n",
       "isFraud           0.000000\n",
       "TransactionID     0.000000\n",
       "Length: 394, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((trainTR.isna().sum()/trainTR.shape[0])*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.066640046296296"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainTR['TransactionDT'].max() - trainTR['TransactionDT'].min())/(60*60*24*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is made from the last 6 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of NaN: 76.35536966166559\n",
      "4           0.000000\n",
      "8           0.000000\n",
      "10        166.215393\n",
      "11          0.000000\n",
      "16          0.000000\n",
      "             ...    \n",
      "590521    451.078796\n",
      "590526      0.000000\n",
      "590529      0.000000\n",
      "590531      0.000000\n",
      "590534      0.000000\n",
      "Name: V202, Length: 139631, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tab = 'V202'\n",
    "print(\"Percent of NaN:\", (trainTR[tab].isna().sum()/trainTR[tab].shape[0])*100)\n",
    "print(trainTR[tab][trainTR[tab].notna()])\n",
    "del tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a strange data, all the VS data are (according to vesta): \"engineered rich features, including ranking, counting, and other entity relations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    569877\n",
      "1     20663\n",
      "Name: isFraud, dtype: int64\n",
      "0    0.96501\n",
      "1    0.03499\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(trainTR['isFraud'].value_counts(normalize=False))\n",
    "print(trainTR['isFraud'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 3.5% (20663) are fraudulous transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we know so far:**\n",
    "\n",
    "Not useful:\n",
    "* TransactionID\n",
    "* TransactionDT\n",
    "* isFraud\n",
    "\n",
    "Transaction Table - Categorical Features:\n",
    "* ProductCD\n",
    "* card1 - card6\n",
    "* addr1, addr2\n",
    "* P_emaildomain\n",
    "* R_emaildomain\n",
    "* M1 - M9\n",
    "\n",
    "Identity Table - Categorical Features:\n",
    "* Categorical Features:\n",
    "* DeviceType\n",
    "* DeviceInfo\n",
    "* id_12 - id_38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Preprocess the data:</h2>\n",
    "\n",
    "* Left join the dataframes\n",
    "* Replace columns with more than 80% NaN with binary data\n",
    "* Convert the NaN\n",
    "* Separate fraudulent transactions from normal\n",
    "* Encode categorical features\n",
    "* Normalize input vectors\n",
    "* Make a validation set from 10% of normal transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace = []\n",
    "\n",
    "def make_hour_feature(f):\n",
    "    #Creates an hour of the day feature, encoded as 0-23.  \n",
    "    hours = f / (3600)        \n",
    "    encoded_hours = np.floor(hours) % 24\n",
    "    return encoded_hours\n",
    "\n",
    "def preprocessData(dataTR, dataID, training=True):\n",
    "    global to_replace\n",
    "    train = pd.merge(dataTR, dataID, on='TransactionID', how='left')\n",
    "    del dataTR; del dataID\n",
    "    \n",
    "    train['hour'] = make_hour_feature(train['TransactionDT'])\n",
    "\n",
    "    cat_features = ['ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain'\n",
    "                    , 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'DeviceType', 'DeviceInfo'\n",
    "                    , 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24'\n",
    "                    , 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37'\n",
    "                    , 'id_38']\n",
    "\n",
    "    exclude = ['TransactionID', 'TransactionDT', 'isFraud']\n",
    "\n",
    "    if(training):\n",
    "        # binary categorical if more than 80% NAs (only numerical)\n",
    "        col_na = train.isna().sum()\n",
    "        to_replace = col_na[(col_na / train.shape[0]) > 0.8].index\n",
    "        to_replace = [f for f in to_replace if f not in cat_features]\n",
    "        print(to_replace)\n",
    "        \n",
    "    num_features = [f for f in train.columns if (f not in to_replace) & (f not in cat_features) & (f not in exclude)]\n",
    "\n",
    "    train[cat_features].astype(str)\n",
    "    train[to_replace].astype(str)\n",
    "    train[num_features].astype(np.float)\n",
    "    \n",
    "    # fill numeric NAs with median\n",
    "    for tab in num_features:\n",
    "        train.loc[train[tab].isnull(), tab] = train[tab].median()\n",
    "\n",
    "    # fill categorical NAs with \"m\" for missing and \"nm\" for not missing\n",
    "    for tab in cat_features:\n",
    "        train.loc[train[tab].isnull(), tab] = \"m\"\n",
    "    for tab in to_replace:\n",
    "        train.loc[train[tab].notnull(), tab] = \"nm\"\n",
    "        train.loc[train[tab].isnull(), tab] = \"m\"\n",
    "    \n",
    "    if(training): train.drop(columns=['TransactionID', 'TransactionDT'], axis=1, inplace=True)\n",
    "    else: train.drop(columns=['TransactionDT'], axis=1, inplace=True)\n",
    "    #train.drop(columns=to_replace, axis=1, inplace=True)\n",
    "        \n",
    "    cat_features = train.select_dtypes(exclude=np.number).columns\n",
    "    \n",
    "    return train, num_features, cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dist2', 'D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id_03', 'id_04', 'id_07', 'id_08', 'id_09', 'id_10']\n"
     ]
    }
   ],
   "source": [
    "train, num_features, cat_features = preprocessData(trainTR, trainID)\n",
    "del trainTR; del trainID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20663\n",
      "569877\n",
      "train NaN: 0\n",
      "fraud NaN: 0\n"
     ]
    }
   ],
   "source": [
    "#Separate fraud from normal transactions\n",
    "\n",
    "fraudData = train.loc[train['isFraud'] == 1, :]\n",
    "train = train.loc[train['isFraud'] == 0, :]\n",
    "print(len(fraudData))\n",
    "print(len(train))\n",
    "print(\"train NaN:\", train.isna().sum().sum())\n",
    "print(\"fraud NaN:\", fraudData.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512889 train examples\n",
      "56988 validation examples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(train[num_features+list(cat_features)], train['isFraud'], test_size=0.1)\n",
    "fraudVal = fraudData['isFraud']\n",
    "fraudData = fraudData[num_features+list(cat_features)]\n",
    "print(len(train_X), 'train examples')\n",
    "print(len(val_X), 'validation examples')\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512889, 678) (56988, 678)\n"
     ]
    }
   ],
   "source": [
    "from category_encoders.binary import BinaryEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def makeTransformer():\n",
    "    # Numerical columns will be scaled by StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Categorical values will be encoded using Binary Encoder\n",
    "    bie = BinaryEncoder()\n",
    "\n",
    "    column_trans = ColumnTransformer(\n",
    "        [('scaler',scaler, num_features),\n",
    "        ('bie', bie, cat_features)], remainder='passthrough', n_jobs=-1)\n",
    "    \n",
    "    return column_trans\n",
    "\n",
    "column_trans = makeTransformer()\n",
    "\n",
    "train_X_transformed = column_trans.fit_transform(train_X)\n",
    "val_X_transformed = column_trans.transform(val_X)\n",
    "\n",
    "del num_features; del cat_features\n",
    "del val_X; del train_X\n",
    "gc.collect()\n",
    "\n",
    "print(train_X_transformed.shape, val_X_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create and train the model</h2>\n",
    "\n",
    "The fun begins here (in my opinion), we will create an autoencoder and compute the mean squared error of the reconstructed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 678)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 544)               369376    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 352)               191840    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 160)               56480     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 96)                15456     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 160)               15520     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 352)               56672     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 544)               192032    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 678)               369510    \n",
      "=================================================================\n",
      "Total params: 1,266,886\n",
      "Trainable params: 1,266,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def makeModel():\n",
    "    inputs = layers.Input(train_X_transformed.shape[1])\n",
    "    x = layers.Dense(544, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l1(1e-5))(inputs)\n",
    "    x = layers.Dense(352, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l1(1e-5))(x)\n",
    "    x = layers.Dense(160, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l1(1e-5))(x)\n",
    "    x = layers.Dense(96, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l1(1e-5))(x)\n",
    "    x = layers.Dense(160, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l1(1e-5))(x)\n",
    "    x = layers.Dense(352, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l1(1e-5))(x)\n",
    "    x = layers.Dense(544, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l1(1e-5))(x)\n",
    "    output = layers.Dense(train_X_transformed.shape[1], activation=\"relu\", activity_regularizer=tf.keras.regularizers.l1(1e-5))(x)\n",
    "\n",
    "    model = Model(inputs, output, name=\"Autoencoder\")\n",
    "    return model\n",
    "\n",
    "model = makeModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "501/501 [==============================] - 20s 33ms/step - loss: 0.0267 - val_loss: 0.0180\n",
      "Epoch 2/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 3/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0142 - val_loss: 0.0135\n",
      "Epoch 4/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 5/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 6/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 7/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 8/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 9/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 11/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 12/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 13/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 14/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 15/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 16/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 17/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 18/50\n",
      "501/501 [==============================] - 18s 37ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 19/50\n",
      "501/501 [==============================] - 16s 33ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 20/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 21/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 22/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 23/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 24/50\n",
      "501/501 [==============================] - 16s 33ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 25/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 26/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 27/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 28/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 29/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 30/50\n",
      "501/501 [==============================] - 17s 34ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 31/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 32/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 33/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 34/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 35/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 36/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 37/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 38/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 39/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 40/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 41/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 42/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 43/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 44/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 45/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 46/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 47/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 48/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 49/50\n",
      "501/501 [==============================] - 16s 32ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 50/50\n",
      "501/501 [==============================] - 16s 31ms/step - loss: 0.0060 - val_loss: 0.0060\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss=tf.keras.losses.MeanSquaredLogarithmicError())\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_X_transformed,\n",
    "    y=train_X_transformed,\n",
    "    validation_data=(val_X_transformed, val_X_transformed),\n",
    "    batch_size=1024,\n",
    "    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"autoencoder_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"autoencoder_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotHistory():\n",
    "    lossV = history.history['loss']\n",
    "    epochs = range(1, len(lossV)+1)\n",
    "\n",
    "    val_lossV = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, lossV, label='Training Loss')\n",
    "    plt.plot(epochs, val_lossV, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "plotHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Determine the threshold for fraud data</h2>\n",
    "\n",
    "To finish we need to determine the threshold (for fraud data) of the reconstruction error (mean squared error).\n",
    "\n",
    "In order to do that we will optimize the sum of true positive percentage and false positive percentage (TP(%) and FP(%))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.00087458 0.0224313  0.00010869 ... 0.00034977 0.00025197 0.00088033], shape=(56988,), dtype=float64)\n",
      "Threshold: 0.003832343673472487\n",
      "\n",
      "fraud acc: 0.5897013986352417\n",
      "val acc: 0.8260335509230013\n",
      "SUM: 1.4157349495582432\n",
      "\n",
      "fraud acc: 0.5991385568407298\n",
      "val acc: 0.8185056503123465\n",
      "SUM: 1.4176442071530762\n",
      "\n",
      "fraud acc: 0.6070754488699608\n",
      "val acc: 0.8111005825787885\n",
      "SUM: 1.4181760314487493\n",
      "\n",
      "fraud acc: 0.6145767797512461\n",
      "val acc: 0.8030638029058749\n",
      "SUM: 1.417640582657121\n",
      "\n",
      "fraud acc: 0.6219813192663215\n",
      "val acc: 0.793816242015863\n",
      "SUM: 1.4157975612821845\n",
      "\n",
      "fraud acc: 0.630305376760393\n",
      "val acc: 0.7841826349406893\n",
      "SUM: 1.4144880117010823\n",
      "\n",
      "fraud acc: 0.6407104486279824\n",
      "val acc: 0.7744612900961606\n",
      "SUM: 1.4151717387241431\n",
      "\n",
      "fraud acc: 0.649808837051735\n",
      "val acc: 0.7632133080648558\n",
      "SUM: 1.4130221451165907\n",
      "\n",
      "fraud acc: 0.659149203891013\n",
      "val acc: 0.7524040148803257\n",
      "SUM: 1.4115532187713387\n",
      "\n",
      "fraud acc: 0.668586362096501\n",
      "val acc: 0.7403663929248263\n",
      "SUM: 1.4089527550213274\n",
      "\n",
      "fraud acc: 0.6791850166965107\n",
      "val acc: 0.7288201024777146\n",
      "SUM: 1.4080051191742253\n",
      "\n",
      "fraud acc: 0.6896384842472052\n",
      "val acc: 0.717168526707377\n",
      "SUM: 1.4068070109545823\n",
      "\n",
      "fraud acc: 0.6994628079175338\n",
      "val acc: 0.704341264827683\n",
      "SUM: 1.4038040727452168\n",
      "\n",
      "fraud acc: 0.7091419445385472\n",
      "val acc: 0.69170702604057\n",
      "SUM: 1.4008489705791172\n",
      "\n",
      "fraud acc: 0.7200793689202923\n",
      "val acc: 0.6775461500666807\n",
      "SUM: 1.397625518986973\n",
      "\n",
      "fraud acc: 0.7310167933020375\n",
      "val acc: 0.6627009194918229\n",
      "SUM: 1.3937177127938605\n",
      "\n",
      "fraud acc: 0.7405507428737357\n",
      "val acc: 0.6481189022250299\n",
      "SUM: 1.3886696450987657\n",
      "\n",
      "fraud acc: 0.7497459226636984\n",
      "val acc: 0.6339931213588825\n",
      "SUM: 1.383739044022581\n",
      "\n",
      "fraud acc: 0.7584571456226105\n",
      "val acc: 0.6181125851056363\n",
      "SUM: 1.3765697307282467\n",
      "\n",
      "fraud acc: 0.7672167642646276\n",
      "val acc: 0.6007756018810978\n",
      "SUM: 1.3679923661457254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def find_threshold(model, x_train_scaled):\n",
    "    reconstructions = model.predict(x_train_scaled)\n",
    "    reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
    "    print(reconstruction_errors)\n",
    "    threshold = np.mean(reconstruction_errors.numpy())\n",
    "    return threshold\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "threshold = find_threshold(model, val_X_transformed)\n",
    "print(f\"Threshold: {threshold}\")\n",
    "\n",
    "def get_predictions(model, x_test_scaled, threshold):\n",
    "    predictions = model.predict(x_test_scaled)\n",
    "    # provides losses of individual instances\n",
    "    predictions = tf.keras.losses.msle(predictions, x_test_scaled)\n",
    "    # 1 = anomaly, 0 = normal\n",
    "    anomaly_mask = pd.Series(predictions) > threshold\n",
    "    predictions = anomaly_mask.map(lambda x: 1.0 if x == True else 0.0)\n",
    "    return predictions\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "fraudData_transformed = column_trans.transform(fraudData)\n",
    "TP = 0; FP = 0; tmp = 0; maxi = 0\n",
    "for i in range(20):\n",
    "    predictions = get_predictions(model, fraudData_transformed, threshold*(1.5-(i*0.05)))\n",
    "    FP = accuracy_score(predictions, fraudVal)\n",
    "\n",
    "    predictions = get_predictions(model, val_X_transformed, threshold*(1.5-(i*0.05)))\n",
    "    TP = accuracy_score(predictions, val_y)\n",
    "    print('\\nfraud acc:', FP)\n",
    "    print('val acc:', TP)\n",
    "    print('SUM:', TP+FP)\n",
    "    if(tmp < TP+FP):\n",
    "        maxi = i\n",
    "        tmp = TP+FP\n",
    "\n",
    "threshold = threshold*(1.5-(maxi*0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5. Test the model !</h2>\n",
    "\n",
    "To conclude we will test the model on fraud data and on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.005365281142861482\n",
      "\n",
      "fraud acc: 0.6070754488699608\n",
      "val acc: 0.8111005825787885\n",
      "\n",
      "SUM: 1.4181760314487493\n"
     ]
    }
   ],
   "source": [
    "predictions = get_predictions(model, fraudData_transformed, threshold)\n",
    "FP = accuracy_score(predictions, fraudVal)\n",
    "\n",
    "predictions = get_predictions(model, val_X_transformed, threshold)\n",
    "TP = accuracy_score(predictions, val_y)\n",
    "\n",
    "print('threshold:', threshold)\n",
    "print('\\nfraud acc:', FP)\n",
    "print('val acc:', TP)\n",
    "print('\\nSUM:', TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are able to make predictions on transactions !\n",
    "\n",
    "Though, 60% of frauds will be detected and 19% of normal transaction will be misclassified which is not enough, in order to improve it we'll have to improve the feature engineering part, or change the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
